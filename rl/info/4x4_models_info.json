{
    "ppo3_1": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "3action",
        "rewards": "-1 for dying, 1 for getting fruit, 100 for winning",
        "gamma": 0.8,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "strength": "strong",
        "notes": "dies randomly sometimes | was trained when the env had a bug"
    },
    "ppo4_2": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "-10 for dying, 10 for getting fruit, -0.00001 if neither",
        "gamma": "0.98",
        "ent_coef": "0.02",
        "learning_rate": "0.0008895296207610578",
        "strength": "strong",
        "notes": "dies randomly sometimes | was trained when the env had a bug"
    },
    "ppo4_3_unbugged_test": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "-10 for dying, 10 for getting fruit, -0.00001 if neither",
        "gamma": 0.98,
        "ent_coef": 0.005,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 10000,
        "strength": "",
        "notes": ""
    },
    "ppo4_3_unbugged": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "-10 for dying, 10 for getting fruit, -0.00001 if neither",
        "gamma": 0.98,
        "ent_coef": 0.005,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 500000,
        "strength": "",
        "notes": ""
    },
    "ppo4_4_more_ent": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "-10 for dying, 10 for getting fruit, -0.00001 if neither",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 500000,
        "strength": "",
        "notes": ""
    },
    "ppo4_5": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "-10 for dying, 10 for getting fruit, -0.00001 if neither",
        "gamma": 0.98,
        "ent_coef": 0.001,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 500000,
        "strength": "",
        "notes": ""
    },
    "ppo4_6": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "-10 for dying, 10 for getting fruit, -0.00001 if neither",
        "gamma": 0.98,
        "ent_coef": 0.02,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 500000,
        "strength": "",
        "notes": ""
    },
    "ppo4_7": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "-1 for dying, 1 for getting fruit, 100 for winning, 0 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 500000,
        "strength": "",
        "notes": ""
    },
    "ppo4_8": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "-1 for dying, 1 for getting fruit, 100 for winning, 0 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.005,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 500000,
        "strength": "",
        "notes": ""
    },
    "ppo4_9": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "-1 for dying, 1 for getting fruit, 100 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.005,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 500000,
        "strength": "",
        "notes": ""
    },
    "ppo4_10": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -16 for dying, 0 for winning (you still get 1 for fruit), -0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.005,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 500000,
        "strength": "",
        "notes": ""
    },
    "ppo4_11": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 0 for winning (you still get 1 for fruit), -0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.005,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 500000,
        "strength": "",
        "notes": ""
    },
    "ppo4_13": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 1 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": ""
    },
    "a2c4_1": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "10 for eating fruit, -10 for dying, 0 for winning, 0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.05,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 500000,
        "strength": "",
        "notes": ""
    },
    "a2c3_1": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "3action",
        "rewards": "10 for eating fruit, -10 for dying, 0 for winning, 0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.05,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 500000,
        "strength": "bad, ~20 avg rewards",
        "notes": ""
    },
    "dqn4_1": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "10 for eating fruit, -10 for dying, 0 for winning, 0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 500000,
        "strength": "",
        "notes": ""
    },
    "dqn4_2": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "10 for eating fruit, -10 for dying, 0 for winning, 0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "win %": 0.0,
        "avg ending snake length": 9.817,
        "stuck %": 0.0,
        "notes": ""
    },
    "a2c4_2": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.05,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 500000,
        "strength": "meh, bad ~2 avg rewards",
        "notes": ""
    },
    "a2c4_3": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.1,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 500000,
        "strength": "",
        "notes": ""
    },
    "ppo4_15": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.05,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 1000000,
        "strength": "",
        "notes": ""
    },
    "ppo4_16": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 1 for winning, 0 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 500000,
        "strength": "",
        "notes": ""
    },
    "ppo4_17": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action_same",
        "rewards": "10 for eating fruit, -10 for dying, 0 for winning, 0 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 1000000,
        "strength": "",
        "notes": ""
    },
    "ppo4_18": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action_same",
        "rewards": "10 for eating fruit, -10 for dying, 0 for winning, 0 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": ""
    },
    "a2c4_5": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -5 for dying, 5 for winning, 0 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 1000000,
        "strength": "",
        "notes": ""
    },
    "dqn4_3": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -5 for dying, 5 for winning, 0 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 700000,
        "strength": "",
        "notes": ""
    },
    "ppo4_19": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, 0 for nothing",
        "gamma": 0.8,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 2000000,
        "strength": "",
        "notes": ""
    },
    "ppo4_22": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, 0 for nothing",
        "gamma": 0.95,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 2000000,
        "strength": "",
        "notes": ""
    },
    "a2c4_6": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, 0 for nothing",
        "gamma": 0.8,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 2000000,
        "strength": "",
        "notes": ""
    },
    "a2c4_7": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, 0 for nothing",
        "gamma": 0.85,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": ""
    },
    "dqn4_4": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, 0 for nothing",
        "gamma": 0.85,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 2000000,
        "strength": "",
        "notes": ""
    },
    "vec8ppo4_4": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "8vec4action",
        "n_envs": 8,
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, 0 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.005,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": ""
    },
    "ppo4_23": {
        "board_size": "4x4",
        "starting_length": 2,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, 0 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 2000000,
        "strength": "",
        "notes": ""
    },
    "vec4ppo4_1": {
        "board_size": "4x4",
        "starting_length": 2,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, 0 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": ""
    },
    "vec4a2c4_1": {
        "board_size": "4x4",
        "starting_length": 2,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, 0 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.05,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 1000000,
        "strength": "",
        "notes": ""
    },
    "vec4a2c4_2": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.95,
        "ent_coef": 0.05,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 1000000,
        "strength": "",
        "notes": ""
    },
    "vec4a2c4_3": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.95,
        "ent_coef": 0.1,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 500000,
        "strength": "",
        "notes": ""
    },
    "vec4a2c4_4": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.95,
        "ent_coef": 0.2,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 1000000,
        "strength": "",
        "notes": ""
    },
    "vec4a2c4_5": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.9,
        "ent_coef": 0.3,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 6000000,
        "strength": "",
        "notes": ""
    },
    "vec4a2c4_6": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.9,
        "ent_coef": 0.25,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 6000000,
        "strength": "",
        "notes": ""
    },
    "vec4a2c4_7": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.9,
        "ent_coef": 0.2,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 6000000,
        "strength": "",
        "notes": ""
    },
    "vec4a2c4_8": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.1,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 6000000,
        "strength": "",
        "notes": ""
    },
    "vec4a2c4_9": {
        "board_size": "4x4",
        "starting_length": 3,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.9,
        "ent_coef": 0.3,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 2000000,
        "strength": "",
        "notes": ""
    },
    "vec4a2c4_10": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -5 for dying, 5 for winning, 0 for nothing",
        "gamma": 0.8,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 3000000,
        "strength": "",
        "notes": ""
    },
    "vec4a2c4_11": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -5 for dying, 5 for winning, 0 for nothing",
        "gamma": 0.8,
        "ent_coef": 0.2,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 3000000,
        "strength": "",
        "notes": ""
    },
    "vec4ppo4_2": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -5 for dying, 5 for winning, 0 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 3000000,
        "strength": "",
        "notes": ""
    },
    "vec4ppo4_3": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -5 for dying, 5 for winning, 0 for nothing",
        "gamma": 0.9,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 3000000,
        "strength": "",
        "notes": ""
    },
    "vec4ppo4_4": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -5 for dying, 5 for winning, 0 for nothing",
        "gamma": 0.95,
        "ent_coef": 0.1,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 3000000,
        "strength": "",
        "notes": ""
    },
    "vec4ppo4_5": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.95,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": ""
    },
    "vec2ppo4_1": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "2vec4action",
        "n_envs": 2,
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.95,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": ""
    },
    "vec4dqn4_1": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.95,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": ""
    },
    "vec4dqn4_2": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4vec4action",
        "n_envs": 4,
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.95,
        "ent_coef": 0.1,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": ""
    },
    "ppo4_25": {
        "board_size": "4x4",
        "starting_length": 3,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.6,
        "ent_coef": 0.01,
        "learning_rate": 0.01,
        "clip_range": 0.2,
        "time_steps": 1000000,
        "strength": "",
        "notes": ""
    },
    "ppo4_26": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 5 for winning, -1 for starving",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.008,
        "time_steps": 1000000,
        "strength": "",
        "notes": "rewards clipped between 10 and -10"
    },
    "a2c4_8": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.9,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 1000000,
        "strength": "",
        "notes": ""
    },
    "ppo4_28": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.9,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 2000000,
        "strength": "",
        "notes": "rewards clipped between 10 and -10"
    },
    "ppo4_29": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 5 for winning, -1 for starving",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 2000000,
        "strength": "",
        "notes": "rewards clipped between 10 and -10"
    },
    "ppo4_test": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 300000,
        "strength": "",
        "notes": ""
    },
    "ppo4_test2": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.02,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 300000,
        "strength": "",
        "notes": ""
    },
    "ppo4_test3": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.005,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 300000,
        "strength": "",
        "notes": ""
    },
    "ppo4_test4": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.0001,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 300000,
        "strength": "",
        "notes": ""
    },
    "ppo4_test5": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 1e-05,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 300000,
        "strength": "",
        "notes": ""
    },
    "dqn4_5": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.0,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 2000000,
        "strength": "",
        "notes": ""
    },
    "dqn4_6": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.0,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 2000000,
        "strength": "",
        "notes": ""
    },
    "dqn4_7": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 5 for winning, -1 for starving",
        "gamma": 0.98,
        "ent_coef": 0.0,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 2000000,
        "strength": "",
        "notes": ""
    },
    "vec4dqn4_3": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.035,
        "exploration_final_eps": 0.02,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": ""
    },
    "vec16dqn4_1": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.035,
        "exploration_final_eps": 0.02,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": ""
    },
    "vec8ppo4_1": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.035,
        "exploration_final_eps": 0.02,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": ""
    },
    "dqn4_8": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.0,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 2000000,
        "strength": "",
        "notes": ""
    },
    "dqn4_9": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.95,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.07,
        "exploration_final_eps": 0.03,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 2000000,
        "strength": "",
        "notes": ""
    },
    "dqn4_10": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.95,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.07,
        "exploration_final_eps": 0.04,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 3000000,
        "win %": 0.1818,
        "avg moves to win": 24.952695269526952,
        "avg ending snake length": 12.4578,
        "stuck %": 0.0,
        "notes": ""
    },
    "a2c4_10": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 5 for winning, -1 for starving",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 2000000,
        "strength": "",
        "notes": ""
    },
    "a2c4_11": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.9,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": ""
    },
    "a2c4_12": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 100 for winning, -0.01 for nothing",
        "gamma": 0.9,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "vec16a2c4_1": {
        "board_size": "4x4",
        "starting_length": 2,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 1 for winning, -0.001 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.035,
        "exploration_final_eps": 0.02,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "a2c4_13": {
        "board_size": "4x4",
        "starting_length": 2,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 1 for winning, -0.001 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "a2c4_14": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 1 for winning, -0.001 for nothing",
        "gamma": 0.9,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "dqn4_12": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 1 for winning, -0.001 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.07,
        "exploration_final_eps": 0.05,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "dqn4_13": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 10 for winning, -0.01 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.07,
        "exploration_final_eps": 0.05,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "dqn4_14": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 10 for winning, -0.01 for nothing",
        "gamma": 0.9,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.07,
        "exploration_final_eps": 0.05,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "dqn4_15": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -10 for dying, 10 for winning, 0 for nothing",
        "gamma": 0.9,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.07,
        "exploration_final_eps": 0.05,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "dqn4_16": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -5 for dying, 5 for winning, 0 for nothing",
        "gamma": 0.9,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.07,
        "exploration_final_eps": 0.05,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "dqn4_17": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -16 for dying, 16 for winning, 0 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.1,
        "exploration_final_eps": 0.07,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "ppo4_34": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -(# of empty squares left) for dying, 1 for winning, -0.001 for nothing",
        "gamma": 0.8,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "win %": 0.5462,
        "avg moves to win": 44.04174295129989,
        "avg ending snake length": 13.0134,
        "stuck %": 0.0242,
        "notes": "backwards -> forwards"
    },
    "ppo4_35": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -(# of empty squares left) for dying, 1 for winning, -0.001 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "ppo4_36": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -width*height for dying, width*height for winning, -0.001 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "ppo4_37": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -width*height for dying, width*height for winning, -0.001 for nothing",
        "gamma": 0.8,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "ppo4_38": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -width*height for dying, width*height for winning, -0.001 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.02,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "dqn4_18": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -width*height for dying, width*height for winning, -0.001 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.1,
        "exploration_final_eps": 0.07,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "dqn4_19": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -width*height for dying, width*height for winning, -0.001 for nothing",
        "gamma": 0.9,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.1,
        "exploration_final_eps": 0.07,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "vec16dqn4_2": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -width*height for dying, width*height for winning, -0.001 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.035,
        "exploration_final_eps": 0.02,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "vec16dqn4_3": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -width*height for dying, width*height for winning, -0.001 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.1,
        "exploration_final_eps": 0.5,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 6000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "vec16dqn4_4": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -width*height for dying, width*height for winning, -0.001 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.6,
        "exploration_final_eps": 0.4,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 6000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "vec16a2c4_2": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -width*height for dying, width*height for winning, -0.001 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.6,
        "exploration_final_eps": 0.4,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 6000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "vec16a2c4_3": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 10 for winning, -0.001 for nothing",
        "gamma": 0.5,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.6,
        "exploration_final_eps": 0.4,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 6000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "dqn4_20": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, width*height for winning, -0.001 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.6,
        "exploration_final_eps": 0.4,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "dqn4_21": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, width*height for winning, -0.001 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.35,
        "exploration_final_eps": 0.02,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "dqn4_22": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, width*height for winning, -0.001 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.45,
        "exploration_final_eps": 0.03,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "dqn4_23": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, width*height for winning, -0.001 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.45,
        "exploration_final_eps": 0.03,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 6000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "dqn4_24": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, width*height for winning, -0.001 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.45,
        "exploration_final_eps": 0.03,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 6000000,
        "strength": "",
        "notes": "backwards -> forwards"
    },
    "a2c4_16": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, width*height for winning, -0.001 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "ending_250_avg_rewards": 5.206752,
        "notes": "backwards -> forwards"
    },
    "ppo4_40": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 1 for winning, -0.001 for nothing",
        "gamma": 0.98,
        "ent_coef": 0.01,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 4000000,
        "ending_250_avg_rewards": 9.828523999999994,
        "win ratio": 0.7496,
        "avg moves to win": 39.57764140875133,
        "avg ending snake length": 260.302,
        "stuck ratio": 0.0,
        "notes": "backwards -> forwards"
    },
    "a2c4_17": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 1 for winning, -1 for starving, -0.001 for nothing",
        "gamma": 0.99,
        "ent_coef": 0.01,
        "learning_rate": 0.001,
        "time_steps": 4000000,
        "ending_250_avg_rewards": 4.552,
        "notes": "backwards -> forwards"
    },
    "a2c4_18": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 1 for winning, -1 for starving, -0.001 for nothing",
        "gamma": 0.99,
        "ent_coef": 0.02,
        "learning_rate": 0.001,
        "time_steps": 4000000,
        "ending_250_avg_rewards": 4.156,
        "notes": "backwards -> forwards"
    },
    "a2c4_19": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 1 for winning, -1 for starving, -0.001 for nothing",
        "gamma": 0.95,
        "ent_coef": 0.02,
        "learning_rate": 0.0008,
        "time_steps": 6000000,
        "ending_250_avg_rewards": 5.124,
        "notes": "backwards -> forwards"
    },
    "vec16a2c4_4": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 1 for winning, -1 for starving, -0.001 for nothing",
        "gamma": 0.5,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.6,
        "exploration_final_eps": 0.4,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 6000000,
        "ending_250_avg_rewards": 0.372864,
        "notes": "backwards -> forwards"
    },
    "vec16a2c4_5": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 1 for winning, -1 for starving, -0.001 for nothing",
        "gamma": 0.98,
        "exploration_fraction": 1,
        "exploration_initial_eps": 0.6,
        "exploration_final_eps": 0.4,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 10000000,
        "ending_250_avg_rewards": 0.738944,
        "notes": "backwards -> forwards"
    },
    "vec16a2c4_6": {
        "board_size": "4x4",
        "starting_length": 4,
        "env": "4action",
        "rewards": "1 for eating fruit, -1 for dying, 1 for winning, -1 for starving, -0.001 for nothing",
        "gamma": 0.95,
        "ent_coef": 0.1,
        "learning_rate": 0.0008895296207610578,
        "time_steps": 10000000,
        "ending_250_avg_rewards": 10.0735,
        "notes": "backwards -> forwards"
    }
}